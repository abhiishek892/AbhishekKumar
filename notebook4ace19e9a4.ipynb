{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":103417,"databundleVersionId":12473839,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.metrics import (accuracy_score, f1_score, roc_auc_score,\n                             mean_squared_error, r2_score, confusion_matrix)\n\n# ===================== SETTINGS =====================\nREMOVE_OUTLIERS = True  # Remove outliers for regression\nVISUALIZE = True        # Generate plots\n\n# ===================== LOAD TRAIN DATA =====================\ndf = pd.read_csv('/kaggle/input/ai-201-b-mse-2-aiml-c/train.csv')\ntarget_col = df.columns[-1]\ndf = df.dropna(subset=[target_col])\nX = df.drop(columns=[target_col])\ny = df[target_col]\n\n# ===================== FEATURE TYPES =====================\nnumeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_cols = X.select_dtypes(include='object').columns.tolist()\n\nprint(\"Feature types summary:\")\nprint(f\"Numeric ({len(numeric_cols)}): {numeric_cols}\")\nprint(f\"Categorical ({len(categorical_cols)}): {categorical_cols}\")\n\n# ===================== TARGET VISUALIZATION =====================\nif VISUALIZE:\n    plt.figure(figsize=(6,4))\n    if y.dtype.kind in 'O' or y.dtype.name == 'category':  # categorical\n        sns.countplot(x=y)\n        plt.title(f\"Target Distribution: {target_col}\")\n    else:\n        sns.histplot(y, kde=True)\n        plt.title(f\"Target Distribution: {target_col}\")\n    plt.show()\n\n# ===================== BOX PLOT =====================\nif VISUALIZE and numeric_cols:\n    plt.figure(figsize=(12,6))\n    X[numeric_cols].boxplot(rot=45)\n    plt.title(\"Boxplots of Numeric Features\")\n    plt.show()\n\n# ===================== CORRELATION HEATMAP =====================\nif VISUALIZE and numeric_cols:\n    plt.figure(figsize=(10,8))\n    corr = X[numeric_cols].corr()\n    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\")\n    plt.title(\"Correlation Heatmap of Numeric Features\")\n    plt.show()\n\n# ===================== CATEGORICAL COUNTS =====================\nif VISUALIZE and categorical_cols:\n    for col in categorical_cols:\n        plt.figure(figsize=(6,4))\n        sns.countplot(x=col, data=X, order=X[col].value_counts().index)\n        plt.title(f\"Counts of {col}\")\n        plt.xticks(rotation=45)\n        plt.show()\n\n# ===================== TASK DETECTION =====================\ndef detect_task(y):\n    if y.dtype.kind in 'biufc' and y.nunique() > 10:\n        return 'regression'\n    else:\n        return 'classification'\n\ntask_type = detect_task(y)\nprint(f\"Detected task type: {task_type}\")\n\n# ===================== TRAIN-TEST SPLIT =====================\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# ===================== OUTLIER REMOVAL =====================\ndef remove_outliers_iqr(df, numeric_cols):\n    df_clean = df.copy()\n    for col in numeric_cols:\n        Q1 = df_clean[col].quantile(0.25)\n        Q3 = df_clean[col].quantile(0.75)\n        IQR = Q3 - Q1\n        lower = Q1 - 1.5 * IQR\n        upper = Q3 + 1.5 * IQR\n        df_clean = df_clean[(df_clean[col] >= lower) & (df_clean[col] <= upper)]\n    return df_clean\n\nif REMOVE_OUTLIERS and task_type == 'regression':\n    train_combined = X_train.copy()\n    train_combined[target_col] = y_train\n    train_clean = remove_outliers_iqr(train_combined, numeric_cols)\n    X_train = train_clean.drop(columns=[target_col])\n    y_train = train_clean[target_col]\n    print(f\"Training rows before: {train_combined.shape[0]}, after: {train_clean.shape[0]}\")\n\n# ===================== TARGET ENCODING =====================\nif task_type == 'classification':\n    le = LabelEncoder()\n    y_train = le.fit_transform(y_train)\n    y_test = le.transform(y_test)\n\n# ===================== PREPROCESSOR =====================\ndef get_preprocessor(numeric_cols, categorical_cols):\n    return ColumnTransformer(transformers=[\n        (\"num\", SimpleImputer(strategy='mean'), numeric_cols),\n        (\"cat_low\", Pipeline([\n            (\"imputer\", SimpleImputer(strategy='most_frequent')),\n            (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n        ]), [col for col in categorical_cols if df[col].nunique() <= 20]),\n        (\"cat_high\", Pipeline([\n            (\"imputer\", SimpleImputer(strategy='most_frequent')),\n            (\"ordinal\", OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))\n        ]), [col for col in categorical_cols if df[col].nunique() > 20])\n    ])\n\npreprocessor = get_preprocessor(numeric_cols, categorical_cols)\n\n# ===================== MODEL =====================\nmodel = RandomForestClassifier(n_estimators=200, max_depth=30, random_state=42) \\\n        if task_type=='classification' else \\\n        RandomForestRegressor(n_estimators=200, max_depth=30, random_state=42)\n\n# ===================== PIPELINE =====================\npipeline = Pipeline([('preprocessor', preprocessor), ('model', model)])\npipeline.fit(X_train, y_train)\n\n# ===================== EVALUATION =====================\ny_pred = pipeline.predict(X_test)\n\nif task_type == 'classification':\n    y_proba = pipeline.predict_proba(X_test)\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n    print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n    if y_proba.shape[1] > 2:\n        print(f\"ROC-AUC (OVR): {roc_auc_score(y_test, y_proba, multi_class='ovr'):.4f}\")\n    else:\n        print(f\"ROC-AUC: {roc_auc_score(y_test, y_proba[:,1]):.4f}\")\n\n    cm = confusion_matrix(y_test, y_pred)\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n                xticklabels=le.classes_,\n                yticklabels=le.classes_)\n    plt.title(\"Confusion Matrix\")\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.show()\nelse:\n    mse = mean_squared_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n    print(f\"Mean Squared Error: {mse:.4f}\")\n    print(f\"R2 Score: {r2:.4f}\")\n\n# ===================== FEATURE IMPORTANCES =====================\n# if VISUALIZE:\n#     num_features = preprocessor.transformers_[0][2]\n#     cat_low_features = preprocessor.transformers_[1][2]\n#     cat_high_features = preprocessor.transformers_[2][2]\n\n#     cat_low_names = pipeline.named_steps['preprocessor'].named_transformers_['cat_low'].named_steps['onehot'].get_feature_names_out(cat_low_features)\n#     cat_high_names = cat_high_features\n\n#     all_features = list(num_features) + list(cat_low_names) + list(cat_high_names)\n#     importances = pipeline.named_steps['model'].feature_importances_\n\n#     feat_imp = pd.DataFrame({\"Feature\": all_features, \"Importance\": importances}).sort_values(by=\"Importance\", ascending=False)\n\n#     plt.figure(figsize=(12,8))\n#     sns.barplot(data=feat_imp.head(15), x=\"Importance\", y=\"Feature\", palette=\"viridis\")\n#     plt.title(\"Top 15 Feature Importances\")\n#     plt.show()\n\n# ===================== LOAD TEST DATA =====================\ndf_test = pd.read_csv('/kaggle/input/ai-201-b-mse-2-aiml-c/test.csv')\ntest_ids = df_test[\"id\"]\nX_test_final = df_test.drop(columns=['id'])\n\n# Add missing columns\nfor col in X_train.columns:\n    if col not in X_test_final.columns:\n        X_test_final[col] = np.nan\nX_test_final = X_test_final[X_train.columns]\n\n# Transform and predict\nX_test_transformed = pipeline.named_steps['preprocessor'].transform(X_test_final)\n\nif task_type == 'classification':\n    y_test_pred = pipeline.predict(X_test_final)\n    y_test_pred = le.inverse_transform(y_test_pred)  # convert back to original labels\n    submission = pd.DataFrame({\n        \"id\": test_ids,\n        \"Prediction\": y_test_pred\n    })\nelse:\n    y_test_pred = pipeline.predict(X_test_transformed)\n    submission = pd.DataFrame({\n        \"id\": test_ids,\n        \"Prediction\": y_test_pred\n    })\n\n\n#submission.insert(0, 'id', test_ids)\nsubmission.to_csv(\"submission_universal.csv\", index=False, float_format=\"%.6f\")\nprint(\"âœ” submission_universal.csv created successfully!\")","metadata":{"id":"JA1veKNY7_KE"},"outputs":[],"execution_count":null}]}